# AI를 활용한 인수 테스트 작성 과정

## 개요

처음 보는 Spring Boot 프로젝트에 대해 AI(Claude Code)를 활용하여 코드 분석부터 인수 테스트 작성, 결과 분석까지 수행한 과정을 정리한 문서입니다.

### 핵심 원칙

- **AI가 작성한 문서를 맹신하지 않는다** — 반드시 실제 코드와 대조하여 검증한다.
- **사람이 방향을 잡고, AI가 실행한다** — 테스트 시나리오 설계는 사람이, 코드 생성은 AI가 담당한다.
- **점진적으로 구체화한다** — 큰 그림 → 세부 계획 → 실제 코드 → 결과 분석 순서로 진행한다.

---

## Step 1. 프로젝트 구조 파악 → ANALYSIS.md

### 프롬프트 전략

단계적으로 질문하여 프로젝트를 파악했다.

1. `"이 프로젝트의 핵심 기능을 분석해줘"` — 전체 구조 파악
2. `"사용자가 할 수 있는 행동은 뭐가 있어?"` — API 기반 행위 정리
3. `"재고가 변경되는 흐름을 보여줘"` — 핵심 비즈니스 로직 추적
4. `"지금까지 분석한 내용을 md파일로 정리해줘"` — 문서화

한 번에 "분석해줘"가 아니라 **관점을 바꿔가며 질문**하면 AI가 놓치는 부분을 줄일 수 있다.

### AI가 수행한 작업

- 디렉토리 구조 탐색 및 계층 구조 정리
- 엔티티 관계도(ERD) 작성
- API 엔드포인트 목록화
- 핵심 비즈니스 로직(재고 변경 흐름) 분석
- 설계 패턴 식별

### 산출물

`ANALYSIS.md` — 프로젝트 개요, 구조, 도메인 모델, API, 비즈니스 로직, 설계 패턴을 포함한 분석 문서

### 이 단계의 포인트

AI는 짧은 시간에 프로젝트 전체를 훑어보고 구조화된 문서를 만들어준다. 사람이 직접 파일을 하나하나 열어보는 것보다 초기 파악 속도가 빠르다. 단, 이 문서는 **초안**이지 **정답**이 아니다.

---

## Step 2. 문서와 실제 코드 대조 → ANALYSIS.md 업데이트

### 프롬프트 전략

AI가 작성한 ANALYSIS.md를 읽으면서 실제 파일을 직접 열어 대조했다. 의문이 생기는 부분은 AI에게 질문하여 확인하고, 틀린 부분은 수정을 요청했다.

### 사람이 수행한 작업

- ANALYSIS.md의 각 항목을 실제 소스 코드와 비교
- 불일치하는 부분 식별 (예: API 요청 형식, 엔티티 세부 사항)
- 의문점을 질문 형태로 정리하여 AI에게 전달

### 발견한 사항 예시

- `Gift`가 `@Entity`가 아니라 Value Object라는 점
- 상품/카테고리 컨트롤러에 `@RequestBody`가 없다는 점
- 옵션/위시리스트/회원 API가 미구현이라는 점
- model에 getter 제외 비즈니스 메서드가 `Option.decrease()` 하나뿐이라는 점
- 서비스 계층도 대부분 단순 CRUD여서 테스트할 비즈니스 로직이 거의 없다는 점

### 실제 API 검증 과정

AI 분석만으로는 부족해서, 실제로 서버를 띄워 curl로 검증했다.

```bash
# form data 방식
curl -d "name=테스트" /api/categories → {"id":1,"name":null}

# JSON 방식
curl -H "Content-Type: application/json" -d '{"name":"테스트"}' /api/categories → {"id":2,"name":null}
```

**결과: 둘 다 `name: null`**. `@RequestBody`가 없어서 JSON이 파싱되지 않고, setter도 없어서 form binding도 실패했다. AI에게 "이거 동작해?"라고 물어보면 코드만 보고 답하지만, **실제로 실행해보면** 다른 결과가 나올 수 있다.

### 이 단계의 포인트

**AI가 만든 문서를 그대로 쓰지 않는 것**이 핵심이다. AI는 코드를 읽을 수 있지만, 맥락을 놓치거나 중요도를 잘못 판단할 수 있다. 사람이 직접 검증하는 과정에서 실제로 중요한 특이사항이 드러난다.

---

## Step 3. 인수 테스트 초안 작성 → Draft.md

### 프롬프트 전략

ANALYSIS.md를 바탕으로, 테스트해야 할 행위 목록과 데이터 전략을 러프하게 정리했다.

### 사람이 직접 작성한 내용

```markdown
## 특이사항
1. 위시리스트 도메인은 있는데 api는 없음
2. 선물 엔티티는 있는데 조회는 없음
3. 회원도 만드는거 없음
4. 생성 api 두개가 데이터를 정상적으로 못받아옴

## 검증할 행위 목록
### 선물 전달 api
1. 정상적으로 선물을 보냄 -> 재고가 줄어든것까지 확인
2. 재고가 부족해서 선물 전달 실패 -> 재고 그대로인거 확인
...
```

### 이 단계의 포인트

AI에게 바로 "테스트 코드 만들어줘"라고 하지 않았다. 먼저 **사람이 무엇을 테스트할지** 정리한 뒤, 이를 AI에게 구체화하도록 넘기는 것이 중요하다. 테스트 시나리오 설계는 도메인 이해가 필요한 작업이므로, 사람이 주도해야 한다.

---

## Step 4. 테스트 계획 구체화 → TEST_STRATEGY.md

### 프롬프트 전략

> "Draft.md 파일을 깔끔하게 정리하고 구체화해줘. 필요하면 ANALYSIS.md는 참고해도 좋아"

초안(Draft.md)의 내용을 AI에게 넘기고, 구조화된 문서로 정리하도록 요청했다.

### AI가 수행한 작업

- 테스트 대상 API를 표로 정리
- 각 시나리오별 기대 결과를 명확히 기술
- 테스트 데이터 전략을 SQL 코드와 함께 구체화
- 검증 전략과 주의사항 정리

### 산출물

`TEST_STRATEGY.md` — 테스트 대상, 시나리오, 데이터 전략, 검증 방법을 포함한 상세 계획

### AI와의 토론에서 수정된 결정들

테스트 전략 수립 과정에서 AI에게 질문하고 토론하면서 여러 결정이 바뀌었다.

**테스트 격리 전략**

AI가 처음에 `@Transactional` 롤백을 추천했다. 하지만 RestAssured는 실제 HTTP 요청을 별도 스레드로 보내기 때문에, 테스트의 트랜잭션과 서버의 트랜잭션이 분리되어 롤백이 적용되지 않는다. 이를 지적하자 AI가 `@Sql` 방식으로 수정했다.

```
테스트 스레드: @Transactional → 롤백
서버 스레드:   별도 트랜잭션 → 이미 커밋됨 → 롤백 안 됨
```

**동시성 테스트의 위치**

AI가 "동시성 테스트는 통합 테스트 영역"이라고 했다. "동시 요청에 대한 차단도 사용자 관점에서 발생하는 일 아닌가?"라고 반론하자 AI가 바로 수긍했다. 다시 "무조건적으로 수용하지 말고 다시 생각해봐"라고 하자, **flaky test 가능성**(스레드 타이밍에 따라 결과가 달라질 수 있음)이라는 현실적 근거를 제시했다. AI의 첫 번째 답변을 그대로 수용하지 않고 재검토를 요청하는 것이 효과적이다.

### 이 단계의 포인트

사람의 러프한 아이디어를 AI가 **구조화하고 빠짐없이 정리**하는 데 강점이 있다. "표로 만들어줘", "빠진 거 없는지 확인해줘" 같은 요청이 효과적이다. 단, **AI가 너무 쉽게 동의하면 의심**해볼 것. "다시 생각해봐"라고 하면 더 나은 근거를 제시하는 경우가 많다.

---

## Step 5. 테스트 케이스 보강

### 프롬프트 전략

> "카테고리가 없을때 상품 생성이 성공하면 안돼. 카테고리의 이름이 null이거나 빈 문자열일때도... 위와 같은 것들을 너가 생각했을때 더 필요한게 있으면 추가해줘. 잘못된 것을 보냈을 때 200이 나오면 안되는데, 200이 나왔을때 그 테스트는 실패하도록 하고 싶은거야."

핵심 시나리오 몇 가지를 직접 지정하면서, **테스트의 의도**(잘못된 입력 → 200이면 실패)를 명확히 전달했다. 그리고 AI에게 같은 맥락에서 추가할 만한 시나리오를 제안하도록 요청했다.

### AI가 추가 제안한 시나리오

| 항목 | 사람이 지정 | AI가 추가 제안 |
|------|-----------|--------------|
| 카테고리 null/빈 이름 | O | |
| 카테고리 중복 이름 | O | |
| 상품 음수 가격 | O | |
| 없는 카테고리로 상품 생성 | O | |
| 상품 null/빈 이름 | | O |
| 선물 수량 0 | | O |
| 선물 수량 음수 | | O |
| 없는 수신자에게 선물 | | O |

### 이 단계의 포인트

**사람이 방향과 의도를 명확히 전달**하면, AI가 같은 패턴의 시나리오를 확장하는 데 효과적이다. "음수 수량으로 선물을 보내면 재고가 오히려 증가한다"는 AI가 코드를 분석해서 찾아낸 구체적인 버그 시나리오였다.

---

## Step 6. 실제 테스트 코드 생성

### 프롬프트 전략

> "이제 TEST_STRATEGY 대로 테스트 코드 작성해줘"

구체화된 계획 문서가 있으므로, AI에게 그대로 구현하도록 요청했다.

### AI가 생성한 파일

```
src/test/
├── resources/sql/
│   ├── truncate.sql          # 테이블 초기화
│   └── test-data.sql         # 테스트 데이터 삽입
└── java/gift/acceptance/
    ├── CategoryAcceptanceTest.java   # 5개 테스트
    ├── ProductAcceptanceTest.java    # 6개 테스트
    └── GiftAcceptanceTest.java       # 7개 테스트 (동시성 포함)
```

### 주요 기술적 결정

- **RestAssured** — 실제 HTTP 요청을 통한 인수 테스트
- **`@Sql` + H2** — 테스트 간 데이터 격리
- **`JdbcTemplate`** — API가 없는 재고 데이터 직접 조회
- **`CountDownLatch`** — 동시성 테스트에서 스레드 동기화

### 이 단계의 포인트

계획 문서가 충분히 구체적이면, AI의 코드 생성 품질이 올라간다. "테스트 코드 만들어줘"보다 "이 문서대로 만들어줘"가 훨씬 정확한 결과를 낸다.

---

## Step 7. 테스트 결과 분석 및 오류 정리

### 실행 결과

**18개 테스트 중 9개 통과, 9개 실패**

### 의도대로 동작한 테스트 (통과)

| 테스트 | 의도 |
|--------|------|
| 카테고리/상품 목록 조회 | 정상 동작 확인 |
| 정상 선물 전달 + 재고 감소 | 핵심 비즈니스 로직 검증 |
| 재고 부족 시 실패 + 재고 유지 | 트랜잭션 롤백 검증 |
| 없는 옵션으로 선물 실패 | 예외 처리 검증 |

### 의도대로 동작한 테스트 (실패 = 프로덕션 버그 발견)

| 테스트 | 발견한 문제 |
|--------|-----------|
| 카테고리/상품 정상 생성 | DTO에 setter 없어 데이터 바인딩 실패 |
| null/빈 이름 카테고리 생성 | 유효성 검증 없음 |
| 중복 이름 카테고리 생성 | unique 제약조건 없음 |
| 0/음수 수량 선물 전달 | 수량 검증 없음 (음수 시 재고 증가 버그) |
| 없는 수신자에게 선물 | 수신자 존재 검증 없음 |
| 동시 선물 전달 | 동시성 제어 없음 |

### 추가 발견: 위양성 테스트

상품 생성 실패 테스트 4건(음수 가격, null 이름, 빈 이름, 없는 카테고리)은 **통과했지만 의도한 이유가 아니었다.**

- 기대: 유효성 검증에 의해 거부 → not 200
- 실제: form 바인딩 자체가 실패해서 `categoryId`가 `null` → `NoSuchElementException` → 500

유효성 검증이 동작해서 통과한 것이 아니라, 바인딩 버그 때문에 우연히 통과한 것이다. 바인딩이 수정되면 이 테스트들은 다시 실패할 것이다.

### 이 단계의 포인트

테스트 결과를 단순히 "통과/실패"로 보지 않고, **왜 통과했는지 / 왜 실패했는지**를 분석하는 것이 중요하다. 특히 위양성(잘못된 이유로 통과)은 사람이 판단해야 하는 영역이다.

---

## 전체 프로세스 요약

```
┌──────────────────────────────────────────────────┐
│  Step 1. AI에게 프로젝트 구조 분석 요청            │
│          → ANALYSIS.md 생성                       │
└──────────────────┬───────────────────────────────┘
                   ▼
┌──────────────────────────────────────────────────┐
│  Step 2. 사람이 문서와 실제 코드를 대조/검증        │
│          → ANALYSIS.md 수정                       │
└──────────────────┬───────────────────────────────┘
                   ▼
┌──────────────────────────────────────────────────┐
│  Step 3. 사람이 테스트 시나리오 초안 작성           │
│          → Draft.md 작성                          │
└──────────────────┬───────────────────────────────┘
                   ▼
┌──────────────────────────────────────────────────┐
│  Step 4. AI에게 초안 구체화 요청                    │
│          → TEST_STRATEGY.md 생성                   │
└──────────────────┬───────────────────────────────┘
                   ▼
┌──────────────────────────────────────────────────┐
│  Step 5. 사람이 시나리오 추가 지시 + AI가 확장      │
│          → TEST_STRATEGY.md 보강                   │
└──────────────────┬───────────────────────────────┘
                   ▼
┌──────────────────────────────────────────────────┐
│  Step 6. AI에게 계획대로 테스트 코드 생성 요청       │
│          → *AcceptanceTest.java 생성               │
└──────────────────┬───────────────────────────────┘
                   ▼
┌──────────────────────────────────────────────────┐
│  Step 7. 테스트 실행 → 사람이 결과 분석             │
│          → 위양성 식별, 프로덕션 버그 목록화          │
└──────────────────────────────────────────────────┘
```

### AI에게 맡기면 효과적인 작업

- 코드베이스 전체 탐색 및 구조 문서화
- 러프한 아이디어를 구조화된 문서로 정리
- 사람이 지정한 패턴을 확장하여 추가 시나리오 제안
- 계획 문서를 기반으로 한 코드 생성

### 사람이 직접 해야 하는 작업

- AI가 만든 문서를 실제 코드와 대조하여 검증
- 무엇을 테스트할지 방향과 의도를 설정
- 테스트 결과에서 위양성/위음성 판별
- 비즈니스 맥락에 기반한 우선순위 결정
